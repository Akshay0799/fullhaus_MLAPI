{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ntTFP6D3N7Y",
        "outputId": "ed0fd1ea-2075-4afc-bd09-8fe6dacb08bc"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDtOa8ZyedG-"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import rescale, resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.applications import VGG16, resnet50\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from numpy import expand_dims\n",
        "import sklearn.preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on8ty5cYlwcY",
        "outputId": "5f431a03-af58-4158-eeaf-a1f978cf6256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt92T8PAeO10"
      },
      "source": [
        "### Loading and Creating Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j97T8hCk6zY3"
      },
      "source": [
        "\n",
        "\n",
        "path = '/content/drive/MyDrive/CV/train_data/'\n",
        "dirs = []\n",
        "X = []\n",
        "y = []\n",
        "fnames = []\n",
        "class_dict = {\n",
        "    \"Bed\": 0,\n",
        "    \"Chair\": 1,\n",
        "    \"Sofa\": 2\n",
        "}\n",
        "\n",
        "for p,dir,fname in os.walk(path):\n",
        "  dirs.append(dir)\n",
        "  fnames.append(fname)\n",
        "del fnames[0]\n",
        "for i in dirs[0]:\n",
        "  for p,dir,fname in os.walk(path+'/'+i+'/'):\n",
        "    for j in fname:\n",
        "      im = np.array((Image.open(path+'/'+i+'/'+j)))\n",
        "      img = resize(im,(128,128))\n",
        "      X.append(img)\n",
        "      y.append(int(class_dict[i]))\n",
        " \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWysvITyfEqL",
        "outputId": "80883f0a-1a8f-472d-cb69-498886373009"
      },
      "source": [
        "print(\"Number of Images in Training set:\",len(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images in Training set: 284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jySbNSujeVra"
      },
      "source": [
        "### Creating Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ricwSJZ-COdB"
      },
      "source": [
        "path = '/content/drive/MyDrive/CV/test_data/'\n",
        "dirs = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "fnames = []\n",
        "\n",
        "for p,dir,fname in os.walk(path):\n",
        "  dirs.append(dir)\n",
        "  fnames.append(fname)\n",
        "del fnames[0]\n",
        "for i in dirs[0]:\n",
        "  for p,dir,fname in os.walk(path+'/'+i+'/'):\n",
        "    for j in fname:\n",
        "      im = np.array((Image.open(path+'/'+i+'/'+j)))\n",
        "      img = resize(im, (128, 128))\n",
        "      X_test.append(img)\n",
        "      y_test.append(int(class_dict[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiUjsKxCDvjA",
        "outputId": "21d4fbb0-a331-4e56-e967-8c277eae079a"
      },
      "source": [
        "print(\"Number of Images in Test set:\",len(X_test)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images in Test set: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing Data Augmentation to improve the training sample"
      ],
      "metadata": {
        "id": "rojMgvkie1Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen1 = ImageDataGenerator(horizontal_flip=True) #horizontal flip\n",
        "datagen2 = ImageDataGenerator(rotation_range=90) #rotation \n",
        "datagen3 = ImageDataGenerator(height_shift_range=0.5) #height_shift\n",
        "# datagen3 = ImageDataGenerator(zoom_range=[0.5,1.0])\n",
        "Xa = []\n",
        "ya = []\n",
        "\n",
        "for i in range(len(X)):\n",
        "  sample = expand_dims(X[i], 0)\n",
        "  it1 = datagen1.flow(sample, batch_size=1)\n",
        "  it2 = datagen2.flow(sample, batch_size=1)\n",
        "  it3 = datagen3.flow(sample, batch_size=1)\n",
        "  # it4 = datagen4.flow(sample, batch_size=1)\n",
        "  im1 = it1.next()[0]\n",
        "  im2 = it2.next()[0]\n",
        "  im3 = it3.next()[0]\n",
        "  # im4 = it4.next()\n",
        "  \n",
        "  ya.append(y[i])\n",
        "  ya.append(y[i])\n",
        "  ya.append(y[i])\n",
        "  ya.append(y[i])\n",
        "\n",
        "  Xa.append(im1)\n",
        "  Xa.append(im2)\n",
        "  Xa.append(im3)\n",
        "  Xa.append(X[i])\n"
      ],
      "metadata": {
        "id": "UD6_-bQ8OQlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Images after augmentation in Training set:\",len(Xa))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75vZ2sxJSKTt",
        "outputId": "54806780-50a7-41a2-c782-126709778e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Images after augmentation in Training set: 1136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSuZg55hcJ4Y"
      },
      "source": [
        "One hot encoding the categorical labels of the target class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nClasses = 3\n",
        "# Use Keras' handy utils\n",
        "\n",
        "ya = tensorflow.keras.utils.to_categorical(ya, num_classes=nClasses)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes=nClasses)"
      ],
      "metadata": {
        "id": "7tnQG9XqkOjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting into NumPy Array"
      ],
      "metadata": {
        "id": "gY-SvA9veSgP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1jBFYWPmgcs"
      },
      "source": [
        "ya=np.array(ya)\n",
        "Xa=np.array(Xa)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifukDLZScP6P"
      },
      "source": [
        "Splitting the training data into training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oW5JYDhFBkh"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(Xa, ya, test_size=1.0/8, stratify=ya, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-4DLq4Ei8VX"
      },
      "source": [
        "X_train = tf.convert_to_tensor(X_train)\n",
        "X_val = tf.convert_to_tensor(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QosyR5fcpVKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8ad678-a02c-4f9d-bc74-4527a5a06751"
      },
      "source": [
        "y_val_k[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3TrmnBBBGfz"
      },
      "source": [
        "## Classification Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkQsmvuScVaZ"
      },
      "source": [
        "Building the classification network on top of the first 4 layers of VGG16 after unfreezing the last layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(128, 128, 3))\n",
        "vgg_model.trainable = False\n",
        "vgg_model.summary()"
      ],
      "metadata": {
        "id": "WdS6cUhihHBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model = Model(inputs = vgg_model.input, outputs = vgg_model.get_layer('block4_pool').output)\n",
        "\n",
        "my_model = models.Sequential()\n",
        "# my_model.add(K.layers.Lambda(lambda image: tf.image.resize(image, (224, 224))))\n",
        "my_model.add(model)\n",
        "\n",
        "# my_model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "# my_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "\n",
        "my_model.add(Flatten())\n",
        "\n",
        "# my_model.add(Dense(units=512,activation=\"relu\"))\n",
        "\n",
        "\n",
        "my_model.add(Flatten())\n",
        "my_model.add(K.layers.BatchNormalization())\n",
        "my_model.add(Dense(units=256,activation=\"relu\"))\n",
        "my_model.add(K.layers.Dropout(0.5))\n",
        "\n",
        "my_model.add(K.layers.BatchNormalization())\n",
        "my_model.add(Dense(units=128,activation=\"relu\"))\n",
        "my_model.add(K.layers.Dropout(0.5))\n",
        "\n",
        "my_model.add(Dense(units=3, activation=\"softmax\"))\n",
        "my_model.summary()\n",
        "\n",
        "# model.add(MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvBYD3dfhK5j",
        "outputId": "450e090a-dde8-4392-a5e3-6d84e29992c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_6 (Functional)        (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8192)             32768     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               2097408   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,879,171\n",
            "Trainable params: 2,147,587\n",
            "Non-trainable params: 14,731,584\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt = tensorflow.keras.optimizers.SGD(lr=0.0008)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "my_model.compile(loss='categorical_crossentropy', \n",
        "                           optimizer=opt, \n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "history_c = my_model.fit(X_train, y_train, batch_size=16, epochs=15, verbose=1, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQbi_YFMhzEm",
        "outputId": "420652af-8ac8-4530-aa7a-936f726be68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "63/63 [==============================] - 7s 57ms/step - loss: 1.0961 - accuracy: 0.5644 - val_loss: 0.6122 - val_accuracy: 0.8521\n",
            "Epoch 2/15\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.5698 - accuracy: 0.7757 - val_loss: 0.3949 - val_accuracy: 0.9155\n",
            "Epoch 3/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4027 - accuracy: 0.8330 - val_loss: 0.2820 - val_accuracy: 0.9296\n",
            "Epoch 4/15\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3274 - accuracy: 0.8632 - val_loss: 0.2047 - val_accuracy: 0.9577\n",
            "Epoch 5/15\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3244 - accuracy: 0.8813 - val_loss: 0.1629 - val_accuracy: 0.9507\n",
            "Epoch 6/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2463 - accuracy: 0.9115 - val_loss: 0.1258 - val_accuracy: 0.9577\n",
            "Epoch 7/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2104 - accuracy: 0.9235 - val_loss: 0.1004 - val_accuracy: 0.9718\n",
            "Epoch 8/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.0863 - val_accuracy: 0.9789\n",
            "Epoch 9/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1741 - accuracy: 0.9437 - val_loss: 0.0778 - val_accuracy: 0.9789\n",
            "Epoch 10/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1638 - accuracy: 0.9477 - val_loss: 0.0732 - val_accuracy: 0.9718\n",
            "Epoch 11/15\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1531 - accuracy: 0.9437 - val_loss: 0.0625 - val_accuracy: 0.9789\n",
            "Epoch 12/15\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.1341 - accuracy: 0.9507 - val_loss: 0.0637 - val_accuracy: 0.9789\n",
            "Epoch 13/15\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1282 - accuracy: 0.9527 - val_loss: 0.0607 - val_accuracy: 0.9789\n",
            "Epoch 14/15\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.0981 - accuracy: 0.9738 - val_loss: 0.0585 - val_accuracy: 0.9789\n",
            "Epoch 15/15\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1055 - accuracy: 0.9678 - val_loss: 0.0550 - val_accuracy: 0.9789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the Model locally"
      ],
      "metadata": {
        "id": "Ybb2zTTDz-c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.save(\"/content/drive/MyDrive/CV/models/vgg_model.h5\")\n",
        "print(\"Saved Model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMv-gkOtz9zy",
        "outputId": "20111c00-2955-4e01-d01d-eab26b0046ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Model and calling the prediction on a single image"
      ],
      "metadata": {
        "id": "TVYgdwA_ewfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/CV/models/vgg_model.h5')\n",
        "path = \"/content/drive/MyDrive/CV/test_data/Chair/Bridgeway Office Chair.jpg\"\n",
        "im = np.array((Image.open(path)))\n",
        "img = resize(im,(128,128))\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "output = model.predict(img).argmax(axis=-1)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5YMcUeS0ifo",
        "outputId": "31c5316a-ff9b-415d-f586-c2254ceb9e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 204ms/step\n",
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX8M2ZXMz7SI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}